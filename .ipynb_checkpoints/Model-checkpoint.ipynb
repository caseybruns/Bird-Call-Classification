{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile #find sampling rate\n",
    "from python_speech_features.python_speech_features import mfcc, logfbank  #had to install\n",
    "import librosa #had to install\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, LSTM\n",
    "from keras.layers import Dropout, Dense, TimeDistributed\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data from `EDA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FILE_PATH/wav_species.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data ready for modeling\n",
    "1. Create Length column\n",
    "2. Create class distribution\n",
    "3. Create probability distribution to sample from\n",
    "4. Remove any audio files that are too short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create Length column\n",
    "df.set_index('wav', inplace=True)\n",
    "for f in df.index:\n",
    "    rate, signal = wavfile.read('clean/'+f)\n",
    "    df.at[f, 'length'] = signal.shape[0]/rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create class distribution\n",
    "classes = list(np.unique(df.bird_names))\n",
    "class_dist = df.groupby(['bird_names'])['length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create probability distribution to sample from\n",
    "n_samples = 2 * int(df['length'].sum()/0.1)\n",
    "prob_dist = class_dist / class_dist.sum()\n",
    "choices = np.random.choice(class_dist.index, p=prob_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Remove any audio files that are too short\n",
    "for f in df.index:\n",
    "    rate, wav = wavfile.read('clean/' + f)\n",
    "    if wav.shape[0]-(rate/2) < 0:\n",
    "        df.drop(f, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data():\n",
    "    if os.path.isfile(config.p_path): #normally don't want config to be global file\n",
    "        print('loading existing data')\n",
    "        with open(config.p_path, 'rb') as handle:\n",
    "            tmp = pickle.load(handle)\n",
    "            return tmp\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "class Config:\n",
    "    def __init__(self, mode='conv', \n",
    "                 nfilt=26, nfeat=13, nfft=512, rate=16000):\n",
    "        self.mode = mode\n",
    "        self.nfilt = nfilt\n",
    "        self.nfeat = nfeat\n",
    "        self.rate = rate\n",
    "        self.nfft = nfft\n",
    "        self.step = int(rate/2)\n",
    "        self.model_path = os.path.join('models', mode + '.model')\n",
    "        self.p_path = os.path.join('pickles', mode + '.pkl')\n",
    "\n",
    "\n",
    "def build_rand_feat():\n",
    "    tmp = check_data()\n",
    "    if tmp:\n",
    "        return tmp.data[0], tmp.data[1]\n",
    "    X = []\n",
    "    y = []\n",
    "    _min, _max = float('inf'), -float('inf')\n",
    "    for _ in tqdm(range(n_samples)):\n",
    "        rand_class = np.random.choice(class_dist.index, p=prob_dist)\n",
    "        file = np.random.choice(df[df.bird_names == rand_class].index)\n",
    "        rate, wav = wavfile.read('clean/' + file)\n",
    "        label = df.at[file, 'bird_names']\n",
    "        rand_index = np.random.randint(0, wav.shape[0]-config.step)\n",
    "        sample = wav[rand_index:rand_index+config.step]\n",
    "        X_sample = mfcc(sample, rate,\n",
    "                       numcep=config.nfeat,\n",
    "                       nfilt=config.nfilt, \n",
    "                       nfft=config.nfft)\n",
    "        _min = min(np.amin(X_sample), _min)\n",
    "        _max = max(np.amax(X_sample), _max)\n",
    "        X.append(X_sample)\n",
    "        y.append(classes.index(label)) #encoding classes 0-9\n",
    "    config.min = _min\n",
    "    config.max = _max\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = (X - _min) / (_max - _min)\n",
    "    if config.mode == 'conv':\n",
    "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "    elif config.mode == 'time':\n",
    "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "    y = to_categorical(y, num_classes=17)\n",
    "    config.data = (X, y)\n",
    "    \n",
    "    with open(config.p_path, 'wb') as handle:\n",
    "        pickle.dump(config, handle, protocol=2) #2 to crossversion (Highest Protocol otherwise)\n",
    "    \n",
    "    return X, y\n",
    "        \n",
    "        \n",
    "def get_conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), activation='relu', strides=(1,1),\n",
    "                    padding='same', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', strides=(1,1), \n",
    "                    padding='same'))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', strides=(1,1), \n",
    "                    padding='same'))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', strides=(1,1), \n",
    "                    padding='same'))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(17, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                 optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 2035250/3087940 [2:06:12<1:02:07, 282.40it/s]"
     ]
    }
   ],
   "source": [
    "config = Config(mode='conv')\n",
    "\n",
    "if config.mode == 'conv':\n",
    "    X, y = build_rand_feat()\n",
    "    y_flat = np.argmax(y, axis=1)\n",
    "    input_shape = (X.shape[1], X.shape[2], 1)\n",
    "    model = get_conv_model()\n",
    "    \n",
    "class_weight = compute_class_weight('balanced', np.unique(y_flat), y_flat)\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(config.model_path, monitor='val_acc',\n",
    "                             verbose=1, mode='max', save_best_only=True,\n",
    "                            save_weights_only=False, period=1)\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor ='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=5)\n",
    "\n",
    "model.fit(X, y, epochs=10, batch_size=32, \n",
    "         shuffle=True, \n",
    "         class_weight=class_weight, validation_split=0.1,\n",
    "         callbacks=[checkpoint, early_stop])\n",
    "\n",
    "model.save(config.model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_predictions(audio_dir):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    fn_prob = {}\n",
    "    print('Extracting features from audio')\n",
    "    for filename in tqdm(os.listdir(audio_dir)):\n",
    "        rate, wav = wavfile.read(os.path.join(audio_dir, filename))\n",
    "        label = fn2class[filename]\n",
    "        c = classes.index(label)\n",
    "        y_prob = []\n",
    "        for i in range(0, wav.shape[0]-config.step, config.step):\n",
    "            sample = wav[i:i+config.step]\n",
    "            x = mfcc(sample, rate,\n",
    "                       numcep=config.nfeat,\n",
    "                       nfilt=config.nfilt, \n",
    "                       nfft=config.nfft)\n",
    "            x = (x - config.min) / (config.max - config.min)\n",
    "            x = x.reshape(1, x.shape[0], x.shape[1], 1)\n",
    "            y_hat = model.predict(x)\n",
    "            y_prob.append(y_hat)\n",
    "            y_pred.append(np.argmax(y_hat))\n",
    "            y_true.append(c)\n",
    "        fn_prob[fn] = np.mean(y_prob, axis=0).flatten()\n",
    "    return y_true, y_pred, fn_prob\n",
    "\n",
    "config = Config(mode='conv')\n",
    "\n",
    "fname = []\n",
    "bird = []    \n",
    "import os,sys\n",
    "folder = 'new_audio/'\n",
    "for filename in os.listdir(folder):\n",
    "    infilename = os.path.join(folder,filename)\n",
    "    if not os.path.isfile(infilename): continue\n",
    "    oldbase = os.path.splitext(filename)\n",
    "    newname = infilename.replace('.m4a', '.wav')\n",
    "    print(newname[:-4].split('/')[1])\n",
    "    fname.append(newname.split('/')[1])\n",
    "    bird.append(newname[:-4].split('/')[1])\n",
    "    output = os.rename(infilename, newname)\n",
    "\n",
    "dct = {}\n",
    "dct['fname'] = fname\n",
    "dct['label'] = bird\n",
    "df = pd.DataFrame(dct)\n",
    "\n",
    "classes = list(np.unique(df.label))\n",
    "fn2class = dict(zip(df.fname, df.label))\n",
    "# p_path = os.path.join('pickles_full', 'conv.p')\n",
    "\n",
    "with open(config.p_path, 'rb') as handle:\n",
    "    config = pickle.load(handle)\n",
    "\n",
    "model = load_model(config.model_path)\n",
    "\n",
    "y_true, y_pred, fn_prob = build_predictions('new_audio')\n",
    "\n",
    "acc_scrore = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "y_probs = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    y_prob = fn_prob[row.fname]\n",
    "    y_probs.append(y_prob)\n",
    "    for c, p in zip(classes, y_prob):\n",
    "        df.at[i, c] = p\n",
    "        \n",
    "\n",
    "y_pred = [classes[np.argmax(y)] for y in y_probs]\n",
    "\n",
    "df['y_pred'] = y_pred\n",
    "\n",
    "df.to_csv('predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
